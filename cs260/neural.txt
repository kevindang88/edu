Today ANNs are being applied to an increasing number of real- world problems of considerable 
complexity. They are good pattern recognition engines and robust classifiers, with the 
ability to generalize in making decisions about imprecise input data. They offer ideal solutions 
to a variety of classification problems such as speech, character and signal recognition, 
as well as functional prediction and system modeling where the physical processes are not 
understood or are highly complex. ANNs may also be applied to control problems, where the
input variables are measurements used to drive an output actuator, and the network learns
the control function.The advantage of ANNs lies in their resilience against distortions 
in the input data and their capability of learning. They are often good at solving problems
that are too complex for conventional technologies (e.g., problems that do not have an 
algorithmic solution or for which an algorithmic solution is too complex to be found) and
are often well suited to problems that people are good at solving, but for which traditional
methods are not. 
Some of the more popular include the 
multilayer perceptron which is generally trained with the backpropagation of error algorithm,
learning vector quantization, radial basis function, Hopfield, and Kohonen, to name a few.
Some ANNs are classified as feedforward while others are recurrent (i.e., implement feedback)
depending on how data is processed through the network. Another way of classifying ANN types
is by their method of learning (or training), as some ANNs employ supervised training while
others are referred to as unsupervised or self-organizing. Supervised training is analogous
to a student guided by an instructor. Unsupervised algorithms essentially perform clustering
of the data into similar groups based on the measured attributes or features serving as inputs
to the algorithms. This is analogous to a student who derives the lesson totally on his or
her own. ANNs can be implemented in software or in specialized hardware. 
Also referred to as connectionist architectures, parallel distributed processing, and neuromorphic 
systems, an artificial neural network (ANN) is an information-processing paradigm inspired
 by the way the densely interconnected, parallel structure of the mammalian brain processes
 information. Artificial neural networks are collections of mathematical models that emulate 
some of the observed properties of biological nervous systems and draw on the analogies 
of adaptive biological learning. The key element of the ANN paradigm is the novel structure
 of the information processing system. 
It is composed of a large number of highly interconnected processing elements that are 
analogous to neurons and are tied together with weighted connections that are analogous to
 synapses. Learning in biological systems involves adjustments to the synaptic connections
 that exist between the neurons. This is true of ANNs as well. Learning typically occurs by
 example through training, or exposure to a truthed set of input/output data where the 
training algorithm iteratively adjusts the connection weights (synapses). These connection
 weights store the knowledge necessary to solve specific problems. Although ANNs have been
 around since the late 1950's, it wasn't until the mid-1980's that algorithms became 
sophisticated enough for general applications. 
